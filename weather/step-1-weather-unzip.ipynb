{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16f4eea-0028-4fd6-a47f-9424586312fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gzip\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec597d-ee53-43e3-95f5-14e15ce1e84d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading the temp.zip and creating a zip object\n",
    "\"\"\"\n",
    "with ZipFile(\"../../../data/noaa.zip\", 'r') as zObject:\n",
    "  \n",
    "    # Extracting all the members of the zip \n",
    "    # into a specific location.\n",
    "    zObject.extractall(path=\"data/noaa/\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6935294d-fb01-4b2d-af67-2bdbec01d073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "verbose = False\n",
    "\n",
    "# process a single .op.gz file\n",
    "def process_opgz (opgz_path):\n",
    "    # read in the data\n",
    "    station_data = []\n",
    "    with gzip.open(opgz_path,'rb') as station_file:\n",
    "        station_contents = station_file.readlines()[1:]\n",
    "    columns = ['STN', 'YEAR', 'MODA', \n",
    "                 'TEMP','DEWP', 'SLP',\n",
    "                 'VISIB', 'WDSP','PRCP', 'SNDP'] # header\n",
    "    # let's extract the data from their character-wise position (seems safest, ref. readme.txt)\n",
    "    station_data += list(map(lambda line : [line[:6], line[14:18], line[18:22], \n",
    "                                            line[24:30], line[35:41], line[46:52],\n",
    "                                            line[68:73], line[78:83], line[118:123], line[125:130]], station_contents))\n",
    "    station_df = pd.DataFrame(station_data, columns=columns)\n",
    "\n",
    "    return station_df\n",
    "\n",
    "# process a single year, i.e., .tar file\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "   \n",
    "def process_tar (tar_path):\n",
    "    clear_output(wait=True)\n",
    "    print(\"Processing year data from file %s..\" % tar_path)\n",
    "    # extract the tarfile\n",
    "    print(' - extracting tarfile.. ', end='', flush=True)\n",
    "    with tarfile.open(tar_path) as tar:\n",
    "        tar.extractall(path='./temp')\n",
    "    print('done.', flush=True)\n",
    "    # process all the op.gz files\n",
    "    print(\" - processing .op.gz files.. \", flush=True)\n",
    "    \n",
    "    year_df = pd.DataFrame(columns=['STN', 'YEAR', 'MODA', \n",
    "                 'TEMP','DEWP', 'SLP',\n",
    "                 'VISIB', 'WDSP','PRCP', 'SNDP'])\n",
    "    station_files = sorted(os.listdir(\"./temp\"))\n",
    "    station_dfs = []\n",
    "    for station_file in tqdm(station_files):\n",
    "        station_df = process_opgz(\"./temp/\"+station_file)\n",
    "        if station_df.shape[0] > 0:\n",
    "            station_dfs.append(station_df)\n",
    "    year_df = pd.concat(station_dfs)\n",
    "    print('    done.', flush=True)\n",
    "    print(\" - removing temporary files.. \", end='', flush=True)\n",
    "    ! rm -r './temp'\n",
    "    print('done.', flush=True)\n",
    "    return year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d488316c-5a53-486c-a1bd-e61eba1b0641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -r './temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa37548-d266-48cf-838d-3406e184e343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/data/repo/mids-capstone-media-attribution/weather\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01f7451d-52f2-45b1-8ca8-c27e2d6e069a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year_files = [\"../../../data/noaa/gsod_all_years/gsod_2007.tar\",\n",
    "              \"../../../data/noaa/gsod_all_years/gsod_2008.tar\",\n",
    "              \"../../../data/noaa/gsod_all_years/gsod_2008.tar\",\n",
    "              \"../../../data/noaa/gsod_all_years/gsod_2010.tar\",\n",
    "              \"../../../data/noaa/gsod_all_years/gsod_2011.tar\",\n",
    "              \"../../../data/noaa/gsod_all_years/gsod_2012.tar\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e21e7da3-1f7b-4051-b2bf-e4b07f93fcd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#year_files = [\"data/noaa/gsod_all_years/gsod_2007.tar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f529a58-4e6d-4b2d-af57-84dbf6cc8736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year data from file data/noaa/gsod_all_years/gsod_2012.tar..\n",
      " - extracting tarfile.. done.\n",
      " - processing .op.gz files.. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11517/11517 [00:10<00:00, 1117.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    done.\n",
      " - removing temporary files.. done.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "year_dfs = []\n",
    "\n",
    "for year_file in year_files:\n",
    "    year_dfs.append(process_tar(year_file))\n",
    "    \n",
    "df_weather = pd.concat(year_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6eb0b85-1894-4cc4-b9fa-18aad230f150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24635200, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28099fe0-0a72-47ab-a0af-a816c4efe942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('../../../data/weather_2007_2012.pkl', 'wb') as f:\n",
    "    pkl.dump(df_weather, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaabfc9b-a8f8-4341-a960-697096c43f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
