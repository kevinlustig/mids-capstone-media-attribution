{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e551019-3753-4496-b15c-94b48825fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "SEED=1\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True\n",
    "\n",
    "GPU = 'cuda:0'\n",
    "START_EPOCH = 0\n",
    "ARCH = 'densenet'\n",
    "EPOCHS = 10\n",
    "LR = .0005\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "PRINT_FREQ = 50\n",
    "BATCH_SIZE = 100\n",
    "WORKERS=2\n",
    "#TRAINDIR=\"data/training/DEWP_class\"\n",
    "#VALDIR=\"data/test/DEWP_class\"\n",
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b14cd7a-c35d-46c8-80f9-10fdf2b15138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "        \n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, scaler, epoch):\n",
    "\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top2 = AverageMeter('Acc@2', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top2],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "                \n",
    "        images = images.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        acc1, acc2 = accuracy(output, target, topk=(1, 2))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top2.update(acc2[0], images.size(0))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "            writer.add_scalar('Train Acc@1',\n",
    "                acc1[0],\n",
    "                epoch * len(train_loader) + i)\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch):\n",
    "\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top2 = AverageMeter('Acc@2', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top2],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            \n",
    "            images = images.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "            \n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            acc1, acc2 = accuracy(output, target, topk=(1, 2))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top2.update(acc2[0], images.size(0))\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "                writer.add_scalar('Validation Acc@1',\n",
    "                    acc1[0],\n",
    "                    epoch * len(val_loader) + i)\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1087af18-507d-40d2-bca3-b2aed22a31c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##From PyTorch docs https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html \n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f57e88-c515-49a2-8c21-1931c0bdeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_init(train_dir, val_dir, num_classes):\n",
    "    model_ft, IMG_SIZE = initialize_model(ARCH, num_classes, False, use_pretrained=False)\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(IMG_SIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB)\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize(IMG_SIZE),\n",
    "        transforms.CenterCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB)\n",
    "    ])\n",
    "\n",
    "    torch.cuda.set_device(GPU)\n",
    "    model_ft.cuda(GPU)\n",
    "    criterion = nn.CrossEntropyLoss().cuda(GPU)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model_ft.parameters(),\n",
    "        lr=LR,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        momentum=MOMENTUM\n",
    "    )\n",
    "    \n",
    "    model = model_ft\n",
    "\n",
    "    # use CosineAnnealingLR\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=EPOCHS)\n",
    "    \n",
    "    train_dataset = torchvision.datasets.ImageFolder(train_dir, transform=transform_train)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "    val_dataset = torchvision.datasets.ImageFolder(val_dir, transform=transform_val)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE, shuffle=True) \n",
    "\n",
    "    return (model, criterion, optimizer, scheduler, scaler, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd99c9f6-b566-4b50-8d20-c7dc05d19523",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_CHECKPOINT_PATH = \"./checkpoint_temp.pth.tar\"\n",
    "DEWP_CHECKPOINT_PATH = \"./checkpoint_dewp.pth.tar\"\n",
    "VISIB_CHECKPOINT_PATH = \"./checkpoint_visib.pth.tar\"\n",
    "WDSP_CHECKPOINT_PATH = \"./checkpoint_wdsp.pth.tar\"\n",
    "\n",
    "TEMP_training_dir = \"../../../data/training/TEMP_class\"\n",
    "TEMP_test_dir = \"../../../data/test/TEMP_class\"\n",
    "DEWP_training_dir = \"../../../data/training/DEWP_class\"\n",
    "DEWP_test_dir = \"../../../data/test/DEWP_class\"\n",
    "VISIB_training_dir = \"../../../data/training/VISIB_class\"\n",
    "VISIB_test_dir = \"../../../data/test/VISIB_class\"\n",
    "WDSP_training_dir = \"../../../data/training/WDSP_class\"\n",
    "WDSP_test_dir = \"../../../data/test/WDSP_class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f228091-0fff-476f-a7f1-fdd75e1483ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/data/venv/lib64/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/data/venv/lib64/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/980]\tTime  5.561 ( 5.561)\tData  0.000 ( 0.000)\tLoss 1.1840e+00 (1.1840e+00)\tAcc@1  31.00 ( 31.00)\tAcc@2  55.00 ( 55.00)\n",
      "Epoch: [0][ 50/980]\tTime  0.857 ( 0.962)\tData  0.000 ( 0.000)\tLoss 1.0413e+00 (1.0772e+00)\tAcc@1  50.00 ( 43.78)\tAcc@2  77.00 ( 75.39)\n",
      "Epoch: [0][100/980]\tTime  0.893 ( 0.919)\tData  0.000 ( 0.000)\tLoss 1.0331e+00 (1.0704e+00)\tAcc@1  44.00 ( 43.82)\tAcc@2  83.00 ( 76.68)\n",
      "Epoch: [0][150/980]\tTime  0.875 ( 0.904)\tData  0.000 ( 0.000)\tLoss 1.0572e+00 (1.0661e+00)\tAcc@1  45.00 ( 44.07)\tAcc@2  80.00 ( 77.44)\n",
      "Epoch: [0][200/980]\tTime  0.877 ( 0.897)\tData  0.000 ( 0.000)\tLoss 1.0855e+00 (1.0650e+00)\tAcc@1  37.00 ( 43.69)\tAcc@2  76.00 ( 77.67)\n",
      "Epoch: [0][250/980]\tTime  0.879 ( 0.893)\tData  0.000 ( 0.000)\tLoss 1.0677e+00 (1.0641e+00)\tAcc@1  46.00 ( 43.59)\tAcc@2  75.00 ( 77.78)\n",
      "Epoch: [0][300/980]\tTime  0.864 ( 0.890)\tData  0.000 ( 0.000)\tLoss 1.0398e+00 (1.0639e+00)\tAcc@1  50.00 ( 43.47)\tAcc@2  77.00 ( 77.78)\n",
      "Epoch: [0][350/980]\tTime  0.876 ( 0.889)\tData  0.000 ( 0.000)\tLoss 1.0419e+00 (1.0629e+00)\tAcc@1  45.00 ( 43.59)\tAcc@2  81.00 ( 77.84)\n",
      "Epoch: [0][400/980]\tTime  0.874 ( 0.887)\tData  0.000 ( 0.000)\tLoss 1.0222e+00 (1.0622e+00)\tAcc@1  51.00 ( 43.61)\tAcc@2  85.00 ( 77.92)\n",
      "Epoch: [0][450/980]\tTime  0.875 ( 0.887)\tData  0.000 ( 0.000)\tLoss 1.0346e+00 (1.0613e+00)\tAcc@1  51.00 ( 43.77)\tAcc@2  77.00 ( 77.96)\n",
      "Epoch: [0][500/980]\tTime  0.879 ( 0.886)\tData  0.000 ( 0.000)\tLoss 1.0815e+00 (1.0611e+00)\tAcc@1  47.00 ( 43.80)\tAcc@2  75.00 ( 77.98)\n",
      "Epoch: [0][550/980]\tTime  0.865 ( 0.885)\tData  0.000 ( 0.000)\tLoss 1.0655e+00 (1.0606e+00)\tAcc@1  47.00 ( 43.89)\tAcc@2  76.00 ( 78.06)\n",
      "Epoch: [0][600/980]\tTime  0.870 ( 0.885)\tData  0.000 ( 0.000)\tLoss 1.0888e+00 (1.0607e+00)\tAcc@1  34.00 ( 43.83)\tAcc@2  75.00 ( 78.06)\n",
      "Epoch: [0][650/980]\tTime  0.876 ( 0.884)\tData  0.000 ( 0.000)\tLoss 1.0946e+00 (1.0607e+00)\tAcc@1  41.00 ( 43.84)\tAcc@2  71.00 ( 78.04)\n",
      "Epoch: [0][700/980]\tTime  0.872 ( 0.884)\tData  0.000 ( 0.000)\tLoss 1.0397e+00 (1.0606e+00)\tAcc@1  46.00 ( 43.84)\tAcc@2  79.00 ( 78.04)\n",
      "Epoch: [0][750/980]\tTime  0.872 ( 0.883)\tData  0.000 ( 0.000)\tLoss 1.0769e+00 (1.0605e+00)\tAcc@1  45.00 ( 43.85)\tAcc@2  72.00 ( 78.07)\n",
      "Epoch: [0][800/980]\tTime  0.883 ( 0.883)\tData  0.000 ( 0.000)\tLoss 1.0903e+00 (1.0605e+00)\tAcc@1  44.00 ( 43.80)\tAcc@2  76.00 ( 78.07)\n",
      "Epoch: [0][850/980]\tTime  0.873 ( 0.882)\tData  0.000 ( 0.000)\tLoss 1.0571e+00 (1.0606e+00)\tAcc@1  39.00 ( 43.77)\tAcc@2  79.00 ( 78.05)\n",
      "Epoch: [0][900/980]\tTime  0.866 ( 0.882)\tData  0.000 ( 0.000)\tLoss 1.0592e+00 (1.0604e+00)\tAcc@1  41.00 ( 43.76)\tAcc@2  76.00 ( 78.07)\n",
      "Epoch: [0][950/980]\tTime  0.876 ( 0.881)\tData  0.000 ( 0.000)\tLoss 1.1026e+00 (1.0601e+00)\tAcc@1  39.00 ( 43.81)\tAcc@2  73.00 ( 78.09)\n",
      "Test: [  0/109]\tTime  0.770 ( 0.770)\tLoss 1.0921e+00 (1.0921e+00)\tAcc@1  39.00 ( 39.00)\tAcc@2  76.00 ( 76.00)\n",
      "Test: [ 50/109]\tTime  0.779 ( 0.774)\tLoss 1.0041e+00 (1.0568e+00)\tAcc@1  54.00 ( 44.02)\tAcc@2  83.00 ( 77.84)\n",
      "Test: [100/109]\tTime  0.761 ( 0.774)\tLoss 1.0525e+00 (1.0551e+00)\tAcc@1  42.00 ( 44.24)\tAcc@2  81.00 ( 78.23)\n",
      "Learning rate: [0.0004877641290737884]\n",
      "Time elapsed: 0:15:48.092870\n",
      "Epoch: [1][  0/980]\tTime  0.880 ( 0.880)\tData  0.000 ( 0.000)\tLoss 1.0295e+00 (1.0295e+00)\tAcc@1  46.00 ( 46.00)\tAcc@2  84.00 ( 84.00)\n",
      "Epoch: [1][ 50/980]\tTime  0.881 ( 0.873)\tData  0.000 ( 0.000)\tLoss 1.0493e+00 (1.0576e+00)\tAcc@1  40.00 ( 43.06)\tAcc@2  82.00 ( 78.47)\n",
      "Epoch: [1][100/980]\tTime  0.873 ( 0.872)\tData  0.000 ( 0.000)\tLoss 1.0316e+00 (1.0563e+00)\tAcc@1  46.00 ( 43.05)\tAcc@2  84.00 ( 78.82)\n",
      "Epoch: [1][150/980]\tTime  0.881 ( 0.872)\tData  0.000 ( 0.000)\tLoss 1.0802e+00 (1.0564e+00)\tAcc@1  37.00 ( 42.99)\tAcc@2  78.00 ( 78.84)\n",
      "Epoch: [1][200/980]\tTime  0.881 ( 0.873)\tData  0.000 ( 0.000)\tLoss 1.0428e+00 (1.0570e+00)\tAcc@1  43.00 ( 43.22)\tAcc@2  78.00 ( 78.49)\n",
      "Epoch: [1][250/980]\tTime  0.875 ( 0.873)\tData  0.000 ( 0.000)\tLoss 1.0471e+00 (1.0578e+00)\tAcc@1  44.00 ( 43.24)\tAcc@2  77.00 ( 78.37)\n",
      "Epoch: [1][300/980]\tTime  0.871 ( 0.873)\tData  0.000 ( 0.000)\tLoss 1.0327e+00 (1.0578e+00)\tAcc@1  49.00 ( 43.26)\tAcc@2  81.00 ( 78.31)\n",
      "Epoch: [1][350/980]\tTime  0.878 ( 0.873)\tData  0.000 ( 0.000)\tLoss 1.0716e+00 (1.0582e+00)\tAcc@1  37.00 ( 43.20)\tAcc@2  78.00 ( 78.23)\n",
      "Epoch: [1][400/980]\tTime  0.874 ( 0.873)\tData  0.000 ( 0.000)\tLoss 1.0927e+00 (1.0574e+00)\tAcc@1  41.00 ( 43.38)\tAcc@2  71.00 ( 78.24)\n",
      "Epoch: [1][450/980]\tTime  0.877 ( 0.873)\tData  0.000 ( 0.000)\tLoss 1.0886e+00 (1.0573e+00)\tAcc@1  36.00 ( 43.46)\tAcc@2  75.00 ( 78.23)\n",
      "Epoch: [1][500/980]\tTime  0.873 ( 0.873)\tData  0.000 ( 0.000)\tLoss 1.0604e+00 (1.0567e+00)\tAcc@1  43.00 ( 43.61)\tAcc@2  79.00 ( 78.27)\n",
      "Epoch: [1][550/980]\tTime  0.887 ( 0.874)\tData  0.000 ( 0.000)\tLoss 1.0880e+00 (1.0565e+00)\tAcc@1  41.00 ( 43.72)\tAcc@2  73.00 ( 78.24)\n",
      "Epoch: [1][600/980]\tTime  0.879 ( 0.874)\tData  0.000 ( 0.000)\tLoss 1.0293e+00 (1.0564e+00)\tAcc@1  47.00 ( 43.76)\tAcc@2  83.00 ( 78.27)\n",
      "Epoch: [1][650/980]\tTime  0.877 ( 0.875)\tData  0.000 ( 0.000)\tLoss 1.0351e+00 (1.0563e+00)\tAcc@1  47.00 ( 43.78)\tAcc@2  82.00 ( 78.31)\n",
      "Epoch: [1][700/980]\tTime  0.879 ( 0.875)\tData  0.000 ( 0.000)\tLoss 9.8010e-01 (1.0559e+00)\tAcc@1  55.00 ( 43.85)\tAcc@2  89.00 ( 78.32)\n",
      "Epoch: [1][750/980]\tTime  0.878 ( 0.875)\tData  0.000 ( 0.000)\tLoss 1.1215e+00 (1.0557e+00)\tAcc@1  36.00 ( 43.88)\tAcc@2  72.00 ( 78.36)\n",
      "Epoch: [1][800/980]\tTime  0.870 ( 0.875)\tData  0.000 ( 0.000)\tLoss 1.1008e+00 (1.0562e+00)\tAcc@1  43.00 ( 43.77)\tAcc@2  74.00 ( 78.31)\n",
      "Epoch: [1][850/980]\tTime  0.867 ( 0.875)\tData  0.000 ( 0.000)\tLoss 1.0493e+00 (1.0559e+00)\tAcc@1  45.00 ( 43.83)\tAcc@2  82.00 ( 78.35)\n",
      "Epoch: [1][900/980]\tTime  0.875 ( 0.875)\tData  0.000 ( 0.000)\tLoss 1.0551e+00 (1.0555e+00)\tAcc@1  39.00 ( 43.90)\tAcc@2  82.00 ( 78.41)\n",
      "Epoch: [1][950/980]\tTime  0.882 ( 0.875)\tData  0.000 ( 0.000)\tLoss 1.0586e+00 (1.0556e+00)\tAcc@1  45.00 ( 43.91)\tAcc@2  76.00 ( 78.36)\n",
      "Test: [  0/109]\tTime  0.782 ( 0.782)\tLoss 9.8904e-01 (9.8904e-01)\tAcc@1  51.00 ( 51.00)\tAcc@2  84.00 ( 84.00)\n",
      "Test: [ 50/109]\tTime  0.771 ( 0.778)\tLoss 1.0144e+00 (1.0504e+00)\tAcc@1  45.00 ( 44.29)\tAcc@2  83.00 ( 78.71)\n",
      "Test: [100/109]\tTime  0.777 ( 0.778)\tLoss 1.0381e+00 (1.0500e+00)\tAcc@1  45.00 ( 44.21)\tAcc@2  80.00 ( 78.60)\n",
      "Learning rate: [0.0004522542485937368]\n",
      "Time elapsed: 0:31:30.878914\n",
      "Epoch: [2][  0/980]\tTime  0.883 ( 0.883)\tData  0.000 ( 0.000)\tLoss 1.0339e+00 (1.0339e+00)\tAcc@1  48.00 ( 48.00)\tAcc@2  78.00 ( 78.00)\n",
      "Epoch: [2][ 50/980]\tTime  0.873 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0084e+00 (1.0500e+00)\tAcc@1  52.00 ( 45.04)\tAcc@2  82.00 ( 78.71)\n",
      "Epoch: [2][100/980]\tTime  0.881 ( 0.875)\tData  0.000 ( 0.000)\tLoss 1.0724e+00 (1.0525e+00)\tAcc@1  39.00 ( 44.72)\tAcc@2  77.00 ( 78.12)\n",
      "Epoch: [2][150/980]\tTime  0.869 ( 0.875)\tData  0.000 ( 0.000)\tLoss 1.0318e+00 (1.0517e+00)\tAcc@1  47.00 ( 44.69)\tAcc@2  81.00 ( 78.30)\n",
      "Epoch: [2][200/980]\tTime  0.890 ( 0.875)\tData  0.000 ( 0.000)\tLoss 1.0653e+00 (1.0532e+00)\tAcc@1  45.00 ( 44.46)\tAcc@2  75.00 ( 78.15)\n",
      "Epoch: [2][250/980]\tTime  0.880 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0502e+00 (1.0537e+00)\tAcc@1  55.00 ( 44.30)\tAcc@2  79.00 ( 78.17)\n",
      "Epoch: [2][300/980]\tTime  0.873 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0355e+00 (1.0531e+00)\tAcc@1  53.00 ( 44.29)\tAcc@2  81.00 ( 78.29)\n",
      "Epoch: [2][350/980]\tTime  0.883 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0318e+00 (1.0522e+00)\tAcc@1  42.00 ( 44.36)\tAcc@2  79.00 ( 78.39)\n",
      "Epoch: [2][400/980]\tTime  0.876 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0851e+00 (1.0517e+00)\tAcc@1  40.00 ( 44.44)\tAcc@2  74.00 ( 78.46)\n",
      "Epoch: [2][450/980]\tTime  0.880 ( 0.875)\tData  0.000 ( 0.000)\tLoss 1.0435e+00 (1.0532e+00)\tAcc@1  46.00 ( 44.30)\tAcc@2  79.00 ( 78.34)\n",
      "Epoch: [2][500/980]\tTime  0.878 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0633e+00 (1.0537e+00)\tAcc@1  43.00 ( 44.22)\tAcc@2  81.00 ( 78.31)\n",
      "Epoch: [2][550/980]\tTime  0.887 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0167e+00 (1.0541e+00)\tAcc@1  50.00 ( 44.23)\tAcc@2  86.00 ( 78.24)\n",
      "Epoch: [2][600/980]\tTime  0.882 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0701e+00 (1.0533e+00)\tAcc@1  40.00 ( 44.32)\tAcc@2  75.00 ( 78.41)\n",
      "Epoch: [2][650/980]\tTime  0.877 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0302e+00 (1.0530e+00)\tAcc@1  43.00 ( 44.34)\tAcc@2  81.00 ( 78.45)\n",
      "Epoch: [2][700/980]\tTime  0.870 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0258e+00 (1.0534e+00)\tAcc@1  47.00 ( 44.27)\tAcc@2  83.00 ( 78.43)\n",
      "Epoch: [2][750/980]\tTime  0.880 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0678e+00 (1.0532e+00)\tAcc@1  43.00 ( 44.26)\tAcc@2  76.00 ( 78.44)\n",
      "Epoch: [2][800/980]\tTime  0.881 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0574e+00 (1.0531e+00)\tAcc@1  41.00 ( 44.27)\tAcc@2  76.00 ( 78.44)\n",
      "Epoch: [2][850/980]\tTime  0.885 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.1115e+00 (1.0530e+00)\tAcc@1  39.00 ( 44.25)\tAcc@2  74.00 ( 78.47)\n",
      "Epoch: [2][900/980]\tTime  0.876 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0608e+00 (1.0530e+00)\tAcc@1  42.00 ( 44.27)\tAcc@2  79.00 ( 78.44)\n",
      "Epoch: [2][950/980]\tTime  0.879 ( 0.876)\tData  0.000 ( 0.000)\tLoss 1.0188e+00 (1.0526e+00)\tAcc@1  48.00 ( 44.33)\tAcc@2  86.00 ( 78.50)\n",
      "Test: [  0/109]\tTime  0.787 ( 0.787)\tLoss 9.9625e-01 (9.9625e-01)\tAcc@1  49.00 ( 49.00)\tAcc@2  87.00 ( 87.00)\n",
      "Test: [ 50/109]\tTime  0.766 ( 0.775)\tLoss 1.0462e+00 (1.0498e+00)\tAcc@1  41.00 ( 44.14)\tAcc@2  82.00 ( 79.02)\n",
      "Test: [100/109]\tTime  0.771 ( 0.775)\tLoss 1.0496e+00 (1.0502e+00)\tAcc@1  42.00 ( 44.45)\tAcc@2  77.00 ( 78.60)\n",
      "Learning rate: [0.0003969463130731183]\n",
      "Time elapsed: 0:47:14.052822\n",
      "Epoch: [3][  0/980]\tTime  0.870 ( 0.870)\tData  0.000 ( 0.000)\tLoss 1.0078e+00 (1.0078e+00)\tAcc@1  48.00 ( 48.00)\tAcc@2  84.00 ( 84.00)\n",
      "Epoch: [3][ 50/980]\tTime  0.891 ( 0.877)\tData  0.000 ( 0.000)\tLoss 1.0767e+00 (1.0459e+00)\tAcc@1  46.00 ( 45.69)\tAcc@2  74.00 ( 78.82)\n"
     ]
    }
   ],
   "source": [
    "model, criterion, optimizer, scheduler, scaler, train_loader, val_loader = single_init(DEWP_training_dir, DEWP_test_dir, num_classes=3)\n",
    "    \n",
    "start = datetime.now()\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "\n",
    "    train(train_loader, model, criterion, optimizer, scaler, epoch)\n",
    "    validate(val_loader, model, criterion, epoch)\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, filename=DEWP_CHECKPOINT_PATH)\n",
    "\n",
    "    scheduler.step()\n",
    "    print('Learning rate: ' + str(scheduler.get_last_lr()))\n",
    "    print(\"Time elapsed: \" + str(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6526f13-32a4-4b42-a2a1-82bde984e1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9130b9e3-8220-47a2-990a-6d39a7d05d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
